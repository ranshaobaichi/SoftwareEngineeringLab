## 单元测试报告
1. 测试目的

本次单元测试旨在验证 PocketLedger 项目中核心业务逻辑在不同输入条件及边界情况下的正确性与稳定性。通过设计覆盖典型分支与边界条件的测试用例，并结合覆盖率工具评估测试充分性，提高系统可靠性。

2. 测试对象

本实验选取以下两个子功能进行单元测试：

预算模型（Budget）
涉及预算阈值判断、超额判断、剩余金额计算、使用率计算以及对象序列化与反序列化等逻辑。

账目查询功能（Database.query_entries）
涉及多条件组合过滤（用户、分类、标签、时间区间、金额区间、关键词）及结果排序逻辑。

3. 测试环境

操作系统：Windows 10

Python 版本：3.12.8

测试框架：pytest

覆盖率工具：pytest-cov

依赖库：icontract

4. 测试工具与方法

使用 pytest 编写单元测试用例，采用 pytest-cov 统计语句覆盖率与分支覆盖率。
对于数据库相关测试，使用 pytest 提供的 tmp_path 机制创建临时 JSON 数据库文件，确保测试环境隔离。

执行命令如下：

pytest -q --cov=pocket_ledger --cov-report=term-missing --cov-branch

5. 单元测试结果与覆盖率分析

Budget 模型
共设计 8 条测试用例，覆盖预算阈值边界、超额判断、剩余金额为负、使用率计算以及序列化与反序列化逻辑。
该模块语句覆盖率为 85%，满足实验要求。

Database.query_entries
共设计 10 余条测试用例，覆盖不同过滤条件及其组合情况，包括时间边界、金额边界及关键词匹配等。
虽然数据库模块整体覆盖率较低，但所选子功能已通过测试用例数量达到实验要求。

6. 测试结论

单元测试结果表明，所选两个子功能在多种边界和组合条件下均能得到预期输出，功能正确。测试覆盖率与测试用例数量均满足实验要求。


## 集成测试报告
一、测试目的

集成测试的目的是在完成单元测试的基础上，验证 PocketLedger 系统中多个模块在组合使用时是否能够正确协同工作。通过对典型业务流程进行测试，检查各模块在真实使用场景下的数据交互、接口调用及整体功能行为是否符合系统设计预期。

二、测试对象与测试方法
1. 测试对象

本次集成测试主要覆盖以下模块的组合使用情况：

业务逻辑聚合层：AppLogic

服务层：AuthService、StatEngine

数据库层：Database

模型层：User、Entry、Category、Budget

未将 UI 层与导出服务（如 Excel/CSV 导出）作为本次集成测试的重点。

2. 测试方法

本实验采用自底向上的集成测试方法（Bottom-Up Integration Testing）。
在模型层与数据库层单元测试通过的基础上，通过业务逻辑聚合层 AppLogic 逐步组合并调用多个模块，验证其在完整业务流程中的协同工作情况。

测试过程中不使用 Mock，对真实模块进行组合测试，并使用临时数据库文件以保证测试环境隔离。

三、集成测试用例设计
集成测试用例一：用户账目管理流程

测试目的
验证用户在完成注册和登录后，是否能够成功添加账目并通过系统接口正确查询到账目信息。

涉及模块

AuthService

Database

Entry

Category

AppLogic

测试流程

初始化 AppLogic，使用临时数据库文件

用户注册

用户登录

获取系统初始化的支出分类

添加一条账目记录

查询账目列表并验证结果

预期结果

用户注册与登录成功

账目能够被成功添加

查询结果中包含新增账目，且账目信息正确

实际结果

测试执行成功，账目成功添加并可被正确查询，测试结果符合预期。

集成测试用例二：预算与统计分析流程

测试目的
验证在存在账目数据的情况下，预算管理模块与统计分析模块是否能够正确协同工作，并返回正确的预算状态信息。

涉及模块

Database

StatEngine

Budget

Entry

AppLogic

测试流程

初始化 AppLogic 并完成用户注册与登录

获取支出分类并添加多条支出账目

添加月度预算

查询预算状态信息

预期结果

当前支出金额计算正确

预算阈值判断正确

未超出预算上限

实际结果

测试执行成功，预算当前金额、阈值触发状态及超额判断结果均与预期一致。

四、集成测试结果与覆盖率分析
1. 测试执行结果

本次集成测试共设计 2 组集成测试用例，所有测试均通过：

32 passed in 0.40s


测试结果表明，在多模块组合使用的情况下，系统核心业务流程能够正确执行。

2. 覆盖率分析

使用 pytest-cov 工具对集成测试执行后的代码覆盖率进行统计，执行命令如下：

pytest -q --cov=pocket_ledger --cov-report=term-missing --cov-branch


覆盖率统计结果显示：

项目整体覆盖率：45%

业务逻辑聚合层（AppLogic）覆盖率：30%

统计分析服务（StatEngine）覆盖率：37%

认证服务（AuthService）覆盖率：48%

相比仅执行单元测试时，AppLogic 与服务层模块的覆盖率均有明显提升，表明集成测试有效覆盖了跨模块调用路径。

由于本次集成测试未覆盖 UI 交互逻辑及文件导出相关功能，相关模块（如 ui_interface.py、export_service.py）的覆盖率相对较低，符合测试设计预期。

五、测试结论

集成测试结果表明，PocketLedger 系统在多个模块组合使用的场景下能够正确协同工作。用户账目管理流程与预算统计分析流程均能按照设计要求正常运行，验证了系统核心业务逻辑的正确性与稳定性。


模糊测试报告
一、模糊测试工具的选取与安装

本项目基于 Python 语言 实现，运行环境为 Windows 操作系统。由于 afl++ 等模糊测试工具主要依赖编译期插桩技术，适用于 C/C++ 等编译型语言，且在 Windows + Python 环境下难以直接使用，因此本实验未采用 afl++ 进行模糊测试。

综合项目语言特性与运行环境限制，本实验选择使用 Hypothesis 作为模糊测试工具。Hypothesis 是 Python 生态中常用的基于属性的模糊测试工具（Property-based Fuzz Testing），能够自动生成大量随机及边界输入，用于检测程序在异常输入条件下的健壮性。

通过以下命令完成工具安装：

pip install hypothesis


（实验中已提供 Hypothesis 安装成功的终端截图作为证明。）

二、模糊测试方法与过程
1. 测试对象选择

本实验选取 Database.query_entries 函数作为模糊测试目标。
该函数具有以下特点：

输入参数数量多（用户 ID、时间区间、金额区间、关键词等）

分支逻辑复杂，包含大量条件判断

易受异常或边界输入影响

不依赖 UI 或文件导出，适合自动化测试

因此，该函数非常适合作为模糊测试对象。

2. 模糊测试方法

采用 Hypothesis 自动输入生成机制，对 query_entries 函数进行模糊测试。
测试过程中，Hypothesis 自动生成不同组合的输入参数，包括：

随机或空值的起始/结束时间

正数、负数及极端数值的金额区间

随机字符串、空字符串作为关键词参数

在每次测试中，使用真实数据库实例和已初始化的账目数据，对目标函数进行调用，检测其在随机和边界输入条件下是否发生异常或程序崩溃。

测试过程中未使用 Mock，所有模块均以真实组合方式参与执行。

3. 测试执行配置

在模糊测试中，使用如下配置控制测试规模：

@settings(max_examples=500)


即由 Hypothesis 自动生成 500 组不同的测试输入，对目标函数进行反复调用。

测试通过 pytest 执行，命令如下：

pytest tests/fuzz_test_query_entries.py -q

## 三、模糊测试结果与分析
1. 测试结果

模糊测试执行结果如下：

1 passed in 4.81s


在 500 组自动生成的随机及边界输入下，程序未发生崩溃或异常终止情况。
Hypothesis 未检测到能够导致测试失败的输入样例。

2. 结果分析

模糊测试结果表明，在大量随机及异常输入条件下，Database.query_entries 函数能够稳定运行，未出现未处理异常或程序崩溃，说明该模块在异常输入场景下具有较好的鲁棒性。

由于 Hypothesis 的工作机制是在发现失败样例时立即终止并保存相关输入，当测试全部通过且未输出 Falsifying example 时，说明在当前测试规模下未发现可导致程序失败的输入。

四、小结

本实验在无法使用 afl++ 的情况下，采用 Hypothesis 作为替代模糊测试工具，对项目中关键函数进行了基于属性的模糊测试。测试结果显示，在大量随机及边界输入条件下，程序能够稳定运行，未出现崩溃情况，验证了系统在异常输入条件下的健壮性。

五、实验截图说明（提交时附）

建议在本节后附以下截图作为实验佐证材料：

Hypothesis 工具安装成功截图

模糊测试代码（fuzz_test_query_entries.py）截图

pytest 执行结果截图（显示 1 passed）